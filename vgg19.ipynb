{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Pierre/Desktop/final_final_try/fer2013.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.emotion.unique()#bytb3 el 7agat el unique mara wa7da "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_label_to_text = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}#by7wl el klam le arkam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.emotion.value_counts()#kol class fi ad eh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(len(df.pixels[0].split(' ')))# dah ely bytl3li el dmiensions. bymsk el pixels y7ot mabenhom space we ygib el len, el sqrt(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure(1, (14, 14))\n",
    "\n",
    "k = 0\n",
    "for label in sorted(df.emotion.unique()):\n",
    "    for j in range(7):\n",
    "        px = df[df.emotion==label].pixels.iloc[k]\n",
    "        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')\n",
    "\n",
    "        k += 1\n",
    "        ax = pyplot.subplot(7, 7, k)\n",
    "        ax.imshow(px, cmap = 'gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(emotion_label_to_text[label])\n",
    "        pyplot.tight_layout()\n",
    "\n",
    "#bytb3 sample mn kol emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = df.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48, 48).astype('float32'))\n",
    "#by5li el pixel vector 2d matrix size 48,48\n",
    "img_array = np.stack(img_array, axis = 0)\n",
    "#by7ot el matrices fi stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features = []\n",
    "\n",
    "for i in range(len(img_array)):\n",
    "    temp = cv2.cvtColor(img_array[i], cv2.COLOR_GRAY2RGB)\n",
    "    #by7wl el sora le 3 channels 3lshan el input dimensions tzbot\n",
    "    img_features.append(temp)\n",
    "\n",
    "img_features = np.array(img_features)\n",
    "print(img_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.imshow(img_features[0].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "img_labels = le.fit_transform(df.emotion)\n",
    "img_labels = to_categorical(img_labels)\n",
    "img_labels.shape\n",
    "################################################33\n",
    "#hna by3ml one hot encoding\n",
    "#1000000-->class 0-->angry\n",
    "#0001000-->class 4-->happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "#hna by3ml mapping maben el classes wel hot enconfind\n",
    "#0 class--->angry// text-->numbers angry--->0       angry(0)---> 0\n",
    "#                                                   happy(1)--> 1\n",
    "#zip dih bt pair kol label bel int value bt3to \n",
    "#dict-->data structure el dictionary\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(img_features, \n",
    "                                                      img_labels, \n",
    "                                                      shuffle = True, \n",
    "                                                      stratify = img_labels, \n",
    "                                                      test_size = 0.1, \n",
    "                                                      random_state = 42)\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape\n",
    "\n",
    "#b2sm el data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del img_features\n",
    "del img_labels\n",
    "\n",
    "#bms7 eli msh m7tago tani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = X_train.shape[1]\n",
    "img_height = X_train.shape[2]\n",
    "img_depth = X_train.shape[3]\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.\n",
    "X_valid = X_valid / 255.\n",
    "#normalize pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = tf.keras.applications.VGG19(weights = 'imagenet',\n",
    "                                  include_top = False,\n",
    "                                  input_shape = (48, 48, 3))\n",
    "\n",
    "#vgg16 model-->weights mn imagenet, include_top-->el dense layers bta3t el vgg msh han5ofha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(bottom_model, classes):\n",
    "    model = bottom_model.layers[-2].output\n",
    "    model = GlobalAveragePooling2D()(model)\n",
    "    model = Dense(classes, activation = 'softmax', name = 'out_layer')(model)\n",
    "    \n",
    "    # el output layer hia el layer -2 mn el vgg \n",
    "    #mwslin el -2 dih bel globalavgpool-->avg filter zai el image bas hay3mlha 3la el image\n",
    "    # kolha msh kernel we ytl3 value wa7da\n",
    "    # el global mtwsl bel output layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = build_model(vgg, num_classes)\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = head)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor = 'val_accuracy', \n",
    "                               min_delta = 0.00005, # el val_acc lazm t3di el min 3lshan yb2a improvment\n",
    "                               patience = 11,# 11 no improvment wara b3d--->stop\n",
    "                               verbose = 1, #flag\n",
    "                               restore_best_weights = True,)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor = 'val_accuracy', \n",
    "                                 factor = 0.5, \n",
    "                                 patience = 7,\n",
    "                                 min_lr = 1e-7,\n",
    "                                 verbose = 1,)\n",
    "\n",
    "callbacks = [early_stopping,lr_scheduler,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation 3lshan ys3ad yw2f el ovwerfitting\n",
    "train_datagen = ImageDataGenerator(rotation_range = 15,\n",
    "                                   width_shift_range = 0.15,\n",
    "                                   height_shift_range = 0.15,\n",
    "                                   shear_range = 0.15,\n",
    "                                   zoom_range = 0.15,\n",
    "                                   horizontal_flip = True,)\n",
    "#dih filters btt3ml 3la el swr\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "epochs = 25\n",
    "optims = optimizers.Adam(learning_rate = 0.0001)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = optims,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        steps_per_epoch=len(X_train) // batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model19.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/Pierre/Desktop/final_final_try/fer2013.csv\")\n",
    "\n",
    "\n",
    "emotion_label_to_text = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}\n",
    "\n",
    "\n",
    "new_model = load_model(\"model19.h5\")\n",
    "\n",
    "\n",
    "yhat_valid = np.argmax(new_model.predict(X_valid), axis=1)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(np.argmax(y_valid, axis=1), yhat_valid)\n",
    "\n",
    "\n",
    "class_names = [emotion_label_to_text[i] for i in range(len(emotion_label_to_text))]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(\"confusion_matrix_dcnn.png\")\n",
    "\n",
    "\n",
    "total_wrong_predictions = np.sum(np.argmax(y_valid, axis=1) != yhat_valid)\n",
    "print(f'Total wrong validation predictions: {total_wrong_predictions}\\n\\n')\n",
    "\n",
    "\n",
    "print(classification_report(np.argmax(y_valid, axis=1), yhat_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
